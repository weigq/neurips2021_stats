{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15b9499",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import sqlite3\n",
    "import datetime\n",
    "import operator\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# from src import DataBase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9030e10",
   "metadata": {},
   "source": [
    "## Get submission list\n",
    "\n",
    "Save urls to txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b107c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_url(panel, url_list, page_id):\n",
    "    # find all items in current page\n",
    "    item_list = panel.find_elements(By.CLASS_NAME, \"note\")\n",
    "    item_list_len = len(item_list)\n",
    "    for i in trange(item_list_len, desc=f\"->{page_id}\"):\n",
    "        # the fist <a> is the paper title and url\n",
    "        item = item_list[i].find_element(By.TAG_NAME, 'a')\n",
    "        url_list.append(item.get_attribute('href').strip()) \n",
    "        \n",
    "        \n",
    "def get_url_list_for_tab(panel, tab_name):\n",
    "    # get totoal page number\n",
    "    _right_arrow = panel.find_elements(By.CLASS_NAME, 'right-arrow')[-1]\n",
    "    total_pages = int(_right_arrow.get_attribute('data-page-number'))\n",
    "    \n",
    "    # loop all pages\n",
    "    url_list = []\n",
    "    for page_id in trange(total_pages, desc=tab_name):\n",
    "        get_item_url(panel, url_list, page_id)\n",
    "        \n",
    "        if page_id == total_pages - 1:\n",
    "            continue\n",
    "        \n",
    "        # the first item\n",
    "        flag = panel.find_element(By.CLASS_NAME, \"note\").text\n",
    "        \n",
    "        time.sleep(1.5)\n",
    "        \n",
    "        # click to jump to next page\n",
    "        next_page_btn = panel.find_element(By.CSS_SELECTOR, \"li[class='  right-arrow']\")\n",
    "        next_page_btn.find_element(By.TAG_NAME, 'a').click()\n",
    "        \n",
    "        # jump to next page\n",
    "        jumped = False\n",
    "        num_try = 0\n",
    "        while not jumped:\n",
    "            time.sleep(1)\n",
    "            _flag = panel.find_element(By.CLASS_NAME, \"note\").text\n",
    "            if _flag != flag:\n",
    "                jumped = True\n",
    "            num_try += 1\n",
    "            if num_try > 1000:\n",
    "                break\n",
    "    \n",
    "    return url_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ac0d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Service('/opt/homebrew/bin/chromedriver')\n",
    "op = Options()\n",
    "op.add_argument('headless')\n",
    "for tab_name in ['oral', 'spotlight', 'poster']:\n",
    "    # driver = webdriver.Chrome(service=s, options=op)\n",
    "    driver = webdriver.Chrome(service=s)\n",
    "    driver.get(f'https://openreview.net/group?id=NeurIPS.cc/2021/Conference#{tab_name}-presentations')\n",
    "    time.sleep(2)\n",
    "    tabpanel = driver.find_element(By.ID, f'{tab_name}-presentations')\n",
    "    url_list = get_url_list_for_tab(tabpanel, tab_name)\n",
    "    \n",
    "    # save to file\n",
    "    save_path = f\"assets/{tab_name}_url_list_\" \\\n",
    "                f\"{datetime.datetime.now():%Y-%m-%d-%H:%M-UTC}.txt\"\n",
    "    with open(save_path, 'w') as f:\n",
    "        f.write('\\n'.join(url_list))  \n",
    "        \n",
    "    # quit\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0d75c2",
   "metadata": {},
   "source": [
    "## Parse each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d3d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read url list\n",
    "url_dict = {}\n",
    "text_files = os.listdir('assets/')\n",
    "for text_file in text_files:\n",
    "    if text_file.endswith('.txt'):\n",
    "        cat = text_file.split('_')[0]\n",
    "        with open(os.path.join('assets', text_file), 'r') as f:\n",
    "            _urls = f.readlines()\n",
    "        for _url in _urls:\n",
    "            if len(_url.strip()) > 0:\n",
    "                url_dict.update({_url: cat})\n",
    "num_items = len(url_dict)\n",
    "print(f'Total {num_items} items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751bf949",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBase:\n",
    "    def __init__(self, db_path: str):\n",
    "        self.db_path = db_path\n",
    "        self.database = None\n",
    "        self.cursor = None\n",
    "        \n",
    "\n",
    "    def initialize(self, create: bool = False):\n",
    "        self.database = sqlite3.connect(self.db_path, check_same_thread=False)\n",
    "        self.cursor = self.database.cursor()\n",
    "  \n",
    "        if create:\n",
    "            _cmd = f\"CREATE TABLE submissions \" \\\n",
    "                   f\"(id int, url text, title text, keywords text, authors text, \" \\\n",
    "                   f\"num_decision int, final_decision text, now_decision text, \" \\\n",
    "                   f\"num_rating int, rating_avg float, rating_std float, ratings text)\"\n",
    "            self.cursor.execute(_cmd)\n",
    "    \n",
    "    def write_item(self, \n",
    "                   _id: int, url: str, title: str, \n",
    "                   keywords: list, authors: str, \n",
    "                   num_decision: int, final_decision: str, now_decision: str, \n",
    "                   ratings: list):\n",
    "        title = title.replace('\\\\', '').replace(\"\\\"\", \"'\")\n",
    "        num_rating = len(ratings)\n",
    "        rating_avg = np.mean(ratings).item()\n",
    "        rating_std = np.std(ratings).item()\n",
    "        ratings = ', '.join(map(str, ratings))\n",
    "        _cmd = f\"insert into submissions values ( \" \\\n",
    "               f\"'{_id}', \\\"{url}\\\", \\\"{title}\\\", \\\"{keywords}\\\", \\\"{authors}\\\", \" \\\n",
    "               f\"'{num_decision}', \\\"{final_decision}\\\", \\\"{now_decision}\\\", \" \\\n",
    "               f\"'{num_rating}', '{rating_avg}', \" \\\n",
    "               f\"'{rating_std}', '{ratings}'\" \\\n",
    "               f\" )\"\n",
    "#         print(_cmd)\n",
    "        self.cursor.execute(_cmd)\n",
    "        self.database.commit()\n",
    "        \n",
    "\n",
    "    def close(self):\n",
    "        self.cursor.close()\n",
    "        self.database.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a548800",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DataBase('assets/neurips2021.db')\n",
    "# db.initialize(create=True)\n",
    "db.initialize(create=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27c541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Service('/opt/homebrew/bin/chromedriver')\n",
    "op = Options()\n",
    "op.add_argument('headless')\n",
    "driver = webdriver.Chrome(service=s, options=op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8651f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = list(url_dict.keys())\n",
    "for i in trange(num_items):\n",
    "    url = url_list[i].strip()\n",
    "    item_id = url.split('id=')[-1]\n",
    "    cat = url_dict[url_list[i]]\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    loaded = False\n",
    "    num_try = 0\n",
    "    while not loaded:        \n",
    "        # comments\n",
    "        _comments = driver.find_element(By.ID, 'note_children')\n",
    "        comments = _comments.find_elements(By.XPATH, \"div[@class='note_with_children comment-level-odd']\")\n",
    "        \n",
    "        if len(comments) > 0:\n",
    "            loaded = True\n",
    "        else:\n",
    "            time.sleep(.5)\n",
    "            assert num_try < 10000, f'Failed to load {url} | tried: {num_try}'\n",
    "            num_try += 1\n",
    "    \n",
    "    item = driver.find_element(By.ID, f'note_{item_id}')\n",
    "\n",
    "    # title\n",
    "    title_el = item.find_element(\n",
    "        By.CSS_SELECTOR, \"div[class='title_pdf_row clearfix']\"\n",
    "    ).find_element(By.CLASS_NAME, 'note_content_title').find_element(By.TAG_NAME, 'a')\n",
    "    item_title = title_el.text.strip()\n",
    "\n",
    "    # authors\n",
    "    author_el = item.find_element(\n",
    "        By.CSS_SELECTOR, \"div[class='meta_row']\"\n",
    "    ).find_element(By.TAG_NAME, 'span').find_elements(By.TAG_NAME, 'a')\n",
    "    item_authors = \", \".join([a.text for a in author_el])\n",
    "\n",
    "    # keywords\n",
    "    key_el = item.find_element(By.CLASS_NAME, 'note_contents').find_elements(By.TAG_NAME, 'span')\n",
    "    assert key_el[0].text == 'Keywords:', f'{url}: Keywords not found!'\n",
    "    item_keywords = key_el[1].text\n",
    "    \n",
    "    # comments\n",
    "    _comments = driver.find_element(By.ID, 'note_children')\n",
    "    comments = _comments.find_elements(By.XPATH, \"div[@class='note_with_children comment-level-odd']\")\n",
    "    \n",
    "    item_ratings = []\n",
    "    two_decision = False\n",
    "    for comment in comments:\n",
    "        keys = comment.find_elements(By.CLASS_NAME, 'note_content_field')\n",
    "        values = comment.find_elements(By.CLASS_NAME, 'note_content_value')\n",
    "        assert len(keys) == len(values), 'key not match with value for {url}'\n",
    "        \n",
    "        # paper decision box\n",
    "        if 'Decision:' in [k.text for k in keys]:\n",
    "            for _k in range(len(keys)):\n",
    "                if keys[_k].text == 'Decision:':  # decesion\n",
    "                    item_final_decision = values[_k].text\n",
    "                    _item_final_decision = item_final_decision.split(' ')[-1].strip('(').strip(')')\n",
    "                    assert _item_final_decision.lower() == cat, f'final decision not match for {url}'\n",
    "                if keys[_k].text == 'Consistency Experiment:':  # \n",
    "                    two_decision = True\n",
    "                    _value = values[_k].text\n",
    "                    _value_re = re.findall(r'.*This copyâ€™s committee reached the following decision: (.*)', _value)\n",
    "                    if len(_value_re) > 0:  \n",
    "                        item_decision = _value_re[0]\n",
    "                    else:  # both \n",
    "                        _value_re = re.findall(r'.*Both committees reached the same decision: (.*)', _value)\n",
    "                        item_decision = _value_re[0]\n",
    "                        \n",
    "        # comemnt box\n",
    "        elif 'Rating:' in [k.text for k in keys]:\n",
    "            for _k in range(len(keys)):\n",
    "                if keys[_k].text == 'Rating:':\n",
    "                    _rating = int(values[_k].text.split(':')[0])\n",
    "                    item_ratings.append(_rating)\n",
    "    if two_decision:\n",
    "        num_decision = 2\n",
    "    else:\n",
    "        num_decision = 1\n",
    "        item_decision = item_final_decision\n",
    "    # print(i, url, item_title, item_keywords, item_authors, item_final_decision, item_decision, item_ratings)\n",
    "    db.write_item(i, url, item_title, item_keywords, item_authors, num_decision, item_final_decision, item_decision, item_ratings)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c5e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f86ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
